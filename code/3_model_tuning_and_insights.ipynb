{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Ames Housing Saleprice Prediction\n",
    "---\n",
    "Project notebook organisation:<br>\n",
    "[1 - Exploratory Data Analysis](./1_exploratory_data_analysis.ipynb)<br>\n",
    "[2 - Preprocessing and Feature Engineering](./2_preprocessing_and_feature_engineering.ipynb)<br>\n",
    "**3 - Model Tuning and Insights** (current notebook)<br>\n",
    "[3.1 - Model Performance with Automated Feature Selection](3_(appendix)_automated_feature_selection)<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T04:26:53.100328Z",
     "start_time": "2019-10-11T04:26:45.908374Z"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, PowerTransformer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, Ridge, RidgeCV, ElasticNet, ElasticNetCV \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "sns.set_style()\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" width=500 align=left><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>\n",
    "<font color = 'grey' size=2>(Figure 1: a visual representation of the model testing process. Source: https://scikit-learn.org/stable/modules/cross_validation.html)</font>\n",
    "\n",
    "This third notebook in this project looks at modeling the data and identifying a suitable production model. The sections in this notebook can be summarised in Fig 1 and as follows:\n",
    "\n",
    "### Contents\n",
    "1. [Import preprocessed data](#Import-preprocessed-data)\n",
    "2. [One-hot encoding](#One-hot-encoding)\n",
    "3. [Train-test-split training data](#Train-test-split-training-data)\n",
    "4. [Scale data](#Scale-data)\n",
    "5. [Hyperparameter tuning](#Hyperparameter-tuning) using training data\n",
    "6. [Cross validation](#Cross-validation) on training data\n",
    "7. [Model evaluation](#Model-evaluation) on test data\n",
    "8. [Production model](#Production-model)\n",
    "9. [Conclusion and recommenations](#Conclusion-and-recommendations)\n",
    "10. [Kaggle submission](#Kaggle-submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import preprocessed data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T04:26:53.202340Z",
     "start_time": "2019-10-11T04:26:53.103438Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train_cleaned.csv\")\n",
    "train.drop_duplicates(keep = False, inplace = True) \n",
    "# remove unnamed and index columns\n",
    "train = train.iloc[:, 2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0836473a245e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Make a few areas have NaN values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "train= pd.DataFrame(np.random.randn(10,6))\n",
    "# Make a few areas have NaN values\n",
    "train.iloc[1:3,1] = np.nan\n",
    "df.iloc[5,3] = np.nan\n",
    "df.iloc[7:9,5] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T04:26:53.229104Z",
     "start_time": "2019-10-11T04:26:53.204334Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "x = float('nan')\n",
    "math.isnan(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T04:26:53.240086Z",
     "start_time": "2019-10-11T04:26:53.231152Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert mssubclass to string again since it got converted back to int on import\n",
    "train['mssubclass'] = train['mssubclass'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "160 features were produced after one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T04:26:53.345478Z",
     "start_time": "2019-10-11T04:26:53.242955Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dummies = pd.get_dummies(train, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T04:26:53.355271Z",
     "start_time": "2019-10-11T04:26:53.347945Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dummies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test-split training data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T04:26:53.394850Z",
     "start_time": "2019-10-11T04:26:53.361701Z"
    }
   },
   "outputs": [],
   "source": [
    "x = train_dummies.loc[:, train_dummies.columns != 'saleprice']\n",
    "y = train_dummies[['saleprice']]\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# train test split\n",
    "np.random.seed(100)\n",
    "xtest, xtrain, ytest, ytrain = train_test_split(x, y, test_size = 0.7, random_state = 7)\n",
    "    # (wrong order but too late to change. but training data is 70% according to shape)\n",
    "    \n",
    "print(xtrain.shape)\n",
    "print(ytrain.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two methods for scaling were tried: \n",
    "1. `StandardScaler` - the standard way to scale data for regularised regressions\n",
    "2. `RobustScaler` - used to scale data with many outliers (which this dataset has)\n",
    "\n",
    "As can be seen later in [Model Evaluation](#Different-feature-engineering-approaches), `StandardScaler` performed better than `RobustScaler`. Scaling of $y$ was also tested, but did not yield good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T04:26:53.421981Z",
     "start_time": "2019-10-11T04:26:53.401765Z"
    }
   },
   "outputs": [],
   "source": [
    "# scale data - standardscaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "xtrain_scaled = scaler.fit_transform(xtrain)\n",
    "xtest_scaled = scaler.transform(xtest)\n",
    "\n",
    "ytrain_scaled = scaler.fit_transform(ytrain)\n",
    "ytest_scaled = scaler.transform(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T04:26:53.428244Z",
     "start_time": "2019-10-11T04:26:53.424981Z"
    }
   },
   "outputs": [],
   "source": [
    "# scale data - robustscaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "xtrain_scaled = scaler.fit_transform(xtrain)\n",
    "# ytrain_scaled = scaler.fit_transform(ytrain)\n",
    "\n",
    "xtest_scaled = scaler.transform(xtest)\n",
    "# ytest_scaled = scaler.transform(ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge $\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T04:27:04.980442Z",
     "start_time": "2019-10-11T04:26:53.432205Z"
    }
   },
   "outputs": [],
   "source": [
    "r_alpha = np.logspace (0,5,200)\n",
    "\n",
    "# fits multiple alphas\n",
    "ridgecv = RidgeCV(alphas = r_alpha, cv = 5)\n",
    "ridgecv = ridgecv.fit(xtrain_scaled, ytrain)\n",
    "\n",
    "print('optimal ridge alpha: ', ridgecv.alpha_)\n",
    "print('best ridge R2: ', ridgecv.score(xtrain_scaled, ytrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso alpha $\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T04:27:05.322562Z",
     "start_time": "2019-10-11T04:27:04.983256Z"
    }
   },
   "outputs": [],
   "source": [
    "l_alpha = np.arange(0.001,0.15,0.0025)\n",
    "\n",
    "# fits multiple alphas\n",
    "lassocv = LassoCV(alphas = l_alpha, cv = 5)\n",
    "lassocv = lassocv.fit(xtrain_scaled, ytrain)\n",
    "\n",
    "print('optimal lasso alpha: ', lassocv.alpha_)\n",
    "print('best lasso R2: ', lassocv.score(xtrain_scaled, ytrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic net $\\lambda$ and $\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T04:27:10.514361Z",
     "start_time": "2019-10-11T04:27:05.324956Z"
    }
   },
   "outputs": [],
   "source": [
    "enet_alpha = np.arange(0, 1, 0.005)\n",
    "enet_ratio = [.01, .1, .2, .3, .5, .7, .9, .95, .99, 1]\n",
    "\n",
    "# fits multiple alphas and rhos\n",
    "enetcv = ElasticNetCV(alphas = enet_alpha, l1_ratio = enet_ratio, cv = 5)\n",
    "enetcv = enetcv.fit(xtrain_scaled, ytrain)\n",
    "\n",
    "print('optimal enet alpha: ', enetcv.alpha_)\n",
    "print('optimal enet lambda: ', enetcv.l1_ratio_)\n",
    "print('best elastic net R2: ', enetcv.score(xtrain_scaled, ytrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four different models were tested using cross validation on training data:\n",
    "1. ordinary linear regression\n",
    "2. ridge regression\n",
    "3. lasso regression\n",
    "4. elastic net regression\n",
    "\n",
    "Their results are summarised below. The **elastic net model performed the best**. Regularised models all performed better than the ordinary linear model, which from its CV performance (extremely large RMSE and extremely small R<sup>2</sup>) appeared to be an extremely poor fit to this dataset (perhaps unsurprisingly so, given the large number of features and complex relationship between them and saleprice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T04:27:10.522611Z",
     "start_time": "2019-10-11T04:27:10.517162Z"
    }
   },
   "outputs": [],
   "source": [
    "# instantiate models with previously selected hyperparameters\n",
    "linmod = LinearRegression()\n",
    "# ridge = Ridge(alpha = ridgecv.alpha_)\n",
    "# lasso = Lasso(alpha = lassocv.alpha_)\n",
    "enet = ElasticNet(alpha = enetcv.alpha_, l1_ratio = enetcv.l1_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T04:27:10.537257Z",
     "start_time": "2019-10-11T04:27:10.525562Z"
    }
   },
   "outputs": [],
   "source": [
    "# define CV function\n",
    "nfolds = 5 \n",
    "np.random.seed(100)\n",
    "\n",
    "def crossval(model, x, y):\n",
    "    kf = KFold(nfolds, shuffle = True, random_state = 7)\n",
    "    rmse = np.sqrt(-cross_val_score(model, x, y, cv = kf, scoring = 'neg_mean_squared_error'))\n",
    "    r2 = cross_val_score(model, x, y, cv = kf)\n",
    "    return 'mean CV R2:', r2.mean(), \\\n",
    "            'mean CV RMSE:', rmse.mean(), \\\n",
    "            'CV R2 variance:', r2.var(), \\\n",
    "            'CV RMSE variance:', rmse.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different model train performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T04:27:11.658450Z",
     "start_time": "2019-10-11T04:27:10.543023Z"
    }
   },
   "outputs": [],
   "source": [
    "# baseline model\n",
    "# use dummy regressor to predict using mean\n",
    "dummy_regressor = DummyRegressor()\n",
    "print('Baseline model: \\n', crossval(dummy_regressor, xtrain_scaled, ytrain))\n",
    "\n",
    "# ordinary linear regression\n",
    "print('SLR: \\n', crossval(linmod, xtrain_scaled, ytrain))\n",
    "\n",
    "# ridge regression\n",
    "# print('RIDGE: \\n', crossval(ridge, xtrain_scaled, ytrain))\n",
    "\n",
    "# lasso regression\n",
    "# print('LASSO: \\n', crossval(lasso, xtrain_scaled, ytrain))\n",
    "\n",
    "# elastic net regression\n",
    "print('ELASTIC NET: \\n', crossval(enet, xtrain_scaled, ytrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further examination of the residual plot also shows generally equal distribution of variance, with the exception of a few points. The plot of predicted $y$ against true $y$ is also genreally linear with a 1:1 relationship, except for a few outliers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different model test performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The four different models from above were evaluated on test data. For both training and test data, the **elastic net model performed the best** and had the highest R<sup>2</sup> and the lowest RMSE, with very little variations between training and test data, indicating an absence of overfitting. On the test data, it was able to explain 91.9% of the variantions in sale price. The ordinary linear model did worse than the baseline model (always predicting the mean of the training data), likely as it produces an extremely biased model with very low variance when trying to find a line of best fit through all 160 of the [original features](#One-hot-encoding). Furthermore, the dataset may contain collinear features, which an ordinary linear model is not robust against.\n",
    "\n",
    "Compared to an ordinary linear regression, regularised regressions apply a penalty term which minimises the coefficients, thereby shrinking the coefficients of the least important features to 0. In this case this reduces the bias compared to a linear regression, by reducing the number of coefficients and enabling the fitting of a more accurate regression line. By scaling the features, coefficients in regularised regression models are also directly represent the importance of the feature in predicting the outcome. This allows one to select a subset of features to include in the final model - those that have the most effect on `saleprice`. As a result, all of the regularised regression methods tested performed better than the ordinary linear regression, and have higher R<sup>2</sup> and lower RMSE scores - meaning that they were able to explain more of the variations in sale price while more accurately predicting the correct sale price. Of these, the elastic net model performed the best.\n",
    "\n",
    "However, regularised regression models are slightly worse for interpretation than an ordinary linear model, as there is no longer a direct relationship between features and the predictor due to the scaling that is done to the features.\n",
    "\n",
    "| Model \t| R2      \t| RMSE    \t|\n",
    "|-------\t|---------\t|---------\t|\n",
    "|Train - baseline model|-0.00203|2.48305\n",
    "|Test - baseline model| -0.00339|2.52438\n",
    "|Train - ordinary linear regression|-2.06381|74488031976|\n",
    "|Test - ordinary linear regression|-1.10334|26471299993|\n",
    "|Train - ridge regression|0.91363|0.72984|\n",
    "|Test - ridge regression|0.91774|0.72278|\n",
    "|Train - lasso regression|0.91759|0.71266|\n",
    "|Test - lasso regression|0.91834|0.72011|\n",
    "|Train - elastic net regression|0.91801|0.71084|\n",
    "|Test - elastic net regression|0.91851|0.71937|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T04:27:11.811237Z",
     "start_time": "2019-10-11T04:27:11.661518Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------- DEFINE ERROR METRICS ---------------------------------------\n",
    "def rmse(ytest, ypred):\n",
    "    return np.sqrt(mean_squared_error(ytest, ypred))\n",
    "\n",
    "# ----------------------------------------- FIT BASELINE MODEL ----------------------------------------\n",
    "# use dummy regressor to predict using mean\n",
    "dummy_regressor = DummyRegressor()\n",
    "baseline_mod = dummy_regressor.fit(xtrain_scaled, ytrain)\n",
    "baseline_pred = dummy_regressor.predict(xtest_scaled)\n",
    "\n",
    "print(f'baseline R2: {dummy_regressor.score(xtest_scaled, ytest)}')\n",
    "print(f'baseline RMSE: {rmse(ytest, baseline_pred)}')\n",
    "\n",
    "# ------------------------------------------- FIT SLR MODEL -------------------------------------------\n",
    "\n",
    "# fit model to train data\n",
    "linmod = linmod.fit(xtrain_scaled, ytrain)\n",
    "# predict on test data\n",
    "ypred = linmod.predict(xtest_scaled)\n",
    "# evaluate model performance\n",
    "print('linmod test R2: ', linmod.score(xtest_scaled, ytest))\n",
    "print('linmod test RMSE: ', rmse(ytest, ypred))\n",
    "\n",
    "# ------------------------------------------ FIT RIDGE MODEL ------------------------------------------\n",
    "\n",
    "# fit model to train data\n",
    "ridge_mod = ridge.fit(xtrain_scaled, ytrain)\n",
    "# predict on test data\n",
    "ypred = ridge_mod.predict(xtest_scaled)\n",
    "# evaluate model performance\n",
    "print('ridge test R2: ', ridge_mod.score(xtest_scaled, ytest))\n",
    "print('ridge test RMSE: ', rmse(ytest, ypred))\n",
    "\n",
    "# ------------------------------------------ FIT LASSO MODEL ------------------------------------------\n",
    "\n",
    "# fit model to train data\n",
    "lasso_mod = lasso.fit(xtrain_scaled, ytrain)\n",
    "# predict on test data\n",
    "ypred = lasso_mod.predict(xtest_scaled)\n",
    "# evaluate model performance\n",
    "print('lasso test R2: ', lasso_mod.score(xtest_scaled, ytest))\n",
    "print('lasso test RMSE: ', rmse(ytest, ypred))\n",
    "\n",
    "# --------------------------------------- FIT ELASTIC NET MODEL ---------------------------------------\n",
    "# fit model to train data\n",
    "enet_mod = enet.fit(xtrain_scaled, ytrain)\n",
    "# predict on test data\n",
    "ypred = enet_mod.predict(xtest_scaled)\n",
    "# evaluate model performance\n",
    "print('elastic net test R2: ', enet_mod.score(xtest_scaled, ytest))\n",
    "print('elastic net test RMSE: ', rmse(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different feature engineering approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the best model from above (elastic net), it was then used to evaluate the test data with different methods for preprocessing and feature engineering (specifically different scaling and transformation methods).\n",
    "\n",
    "Due to how $y$ was transformed for each model, the RMSE of the different models tested were not directly comparable. Therefore, R<sup>2</sup> was used to select the best method for preprocessing. \n",
    "\n",
    "Six different methods were tested, using different ways to engineer feature as listed below. **Method three performed the best** with the highest R<sup>2</sup> score, and had very little difference between train and test results. In general, methods where y was transformed performed better (model one and three). Method six performed the worst, when saleprice was scaled.\n",
    "\n",
    "**Method One**\n",
    "- `saleprice` was log transformed\n",
    "- transformation of skewed features: log transform for positively skewed features, square transform for negatively skewed features\n",
    "- `StandardScaler` used on $x$ features\n",
    "\n",
    "**Method Two**\n",
    "- `saleprice` was not transformed \n",
    "- transformation of skewed features: log transform for positively skewed features, square transform for negatively skewed features\n",
    "- `StandardScaler` used on $x$ features\n",
    "\n",
    "**Method Three**\n",
    "- `saleprice` was Box-Cox transformed\n",
    "- transformation of skewed features: Box-Cox for all\n",
    "- `StandardScaler` used on $x$ features\n",
    "\n",
    "**Method Four**\n",
    "- `saleprice` was not transformed\n",
    "- transformation of skewed features: Box-Cox for all\n",
    "- `StandardScaler` used on $x$ features\n",
    "\n",
    "**Method Five**\n",
    "- same transformations as model 3 \n",
    "- `RobustScaler` used  on $x$ features instead of `StandardScaler`\n",
    "\n",
    "**Method Six**\n",
    "- same transformations as model 3 \n",
    "- `StandardScaler` used on $x$ features _and_ `saleprice`\n",
    "\n",
    "The results are summarised below:\n",
    "\n",
    "| Method \t| R2      \t| RMSE    \t|\n",
    "|-------\t|---------\t|---------\t|\n",
    "| 1 train\t| 0.91660 \t| 0.11740 \t|\n",
    "| 1 test\t| 0.90264 \t| 0.12842 \t|\n",
    "| 2 train  \t| 0.88188 \t| 26746   \t|\n",
    "| 2 test   \t| 0.88738 \t| 26852   \t|\n",
    "| 3 train \t| 0.91808  \t| 0.71047  \t|\n",
    "| 3 test\t| 0.91925 \t| 0.71612 \t|\n",
    "| 4 train \t| 0.89358  \t| 26074 \t|\n",
    "| 4 test\t| 0.88605 \t| 25903 \t|\n",
    "| 5 train\t| 0.91697 \t| 0.11715 \t|\n",
    "| 5 test\t| 0.90345 \t| 0.12789 \t|\n",
    "| 6 train\t| 0.92397 \t| 0.27428 \t|\n",
    "| 6 test\t| -43.032 \t| 6.66700 \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T04:27:11.869368Z",
     "start_time": "2019-10-11T04:27:11.814006Z"
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------- FIT ELASTIC NET MODEL ---------------------------------------\n",
    "# fit model to train data\n",
    "enet_mod = enet.fit(xtrain_scaled, ytrain)\n",
    "# predict on test data\n",
    "ypred = enet_mod.predict(xtest_scaled)\n",
    "# evaluate model performance\n",
    "print('enet test R2: ', enet_mod.score(xtest_scaled, ytest))\n",
    "print('enet test RMSE: ', rmse(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual plots of best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further examination of the residual plot using the elastic net model along with method 3 shows generally equal distribution of variance, with the exception of a few points. The plot of predicted y against true y is also genreally linear with a 1:1 relationship, except for a few outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T04:31:43.737514Z",
     "start_time": "2019-10-11T04:31:43.435220Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot residuals\n",
    "resid = ypred - ytest.saleprice\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (6.0, 5.0)\n",
    "plt.scatter(ytest.saleprice, resid)\n",
    "plt.axhline(0, linestyle='-', color='r')\n",
    "plt.title('residual distribution plot',fontsize=14)\n",
    "plt.xlabel('actual values',fontsize=12)\n",
    "plt.ylabel('residuals',fontsize=12)\n",
    "plt.plot([], [], ' ', label=\"model: elastic net\")\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T04:31:33.620804Z",
     "start_time": "2019-10-11T04:31:33.292263Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot ypred vs ytrue\n",
    "fig, ax = plt.subplots(figsize=(6.0, 6.0))\n",
    "ax.scatter(ytest.saleprice, ypred)\n",
    "ax.set_title('predicted values distribution plot',fontsize=14)\n",
    "ax.set_xlabel('actual values',fontsize=12)\n",
    "ax.set_ylabel('predicted values',fontsize=12)\n",
    "ax.set_xlim(20,45)\n",
    "ax.set_ylim(20,45)\n",
    "ax.plot(ax.get_xlim(), ax.get_ylim(), ls=\"-\", c=\"r\")\n",
    "plt.plot([], [], ' ', label=\"model: elastic net\")\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an easy to interpret production model, it is necessary to reduce the number of features even further than those selected by the regularised elastic net model (the top model produced 104 non-zero coefficients). This was done using the coefficients obtained from the best model above - cross validation was done on training data to calculate mean validation set MSE and standard errors (SE) for different numbers of coefficients. First, the feature with the highest absolute coefficient was used. Then the feature with the second-highest absolute coefficient was added to the training data, and so on until all 104 features with non-zero coefficients were included in the training data.\n",
    "\n",
    "The validation set errors are then plotted against number of predictors. MSE appears to stop decreasing significantly from 30 predictors onwards. Using the [one-standard-error-rule](https://www.stat.cmu.edu/~ryantibs/datamining/lectures/19-val2.pdf), the smallest model for which the test MSE is within one SE of the MSE of 30 predictors is 19 (as shown where the red line crosses the black line in the graph) - if two means are within one SE of each other, there is usually no sigificant difference in the means. Therefore, for the purpose of having a simpler and more easily interpretable model, the **top 19 predictors** will be used for the production model. These are:\n",
    "\n",
    "|Predictor|Coefficient|\n",
    "|---|---|\n",
    "|grlivarea \t|0.924321|\n",
    "|overallqual |\t0.441007|\n",
    "|overallcond |\t0.338053|\n",
    "|age_sold \t|-0.294810|\n",
    "|lotarea \t|0.256735|\n",
    "|bsmtfinsf1 |\t0.232905|\n",
    "|yearbuilt \t|0.199919|\n",
    "|neighborhood_NridgHt| \t0.159834|\n",
    "|garagearea \t|0.140222|\n",
    "|bsmtqual \t|0.131523|\n",
    "|bsmtexposure |\t0.125544|\n",
    "|mszoning_C (all)| \t-0.119000|\n",
    "|mssubclass_20 \t|0.117647|\n",
    "|neighborhood_StoneBr| \t0.111131|\n",
    "|kitchenqual \t|0.107051|\n",
    "|neighborhood_NoRidge |\t0.103183|\n",
    "|exterqual \t|0.096834|\n",
    "|fireplaces |\t0.095645|\n",
    "|exterior_Brick| \t0.091763|\n",
    "\n",
    "<font size=2>\\* neighborhood_GrnHill was removed as the sample size in the training data was only 2, therefore may not give accurate predictions.</font>\n",
    "\n",
    "These coefficients are also illustrated in the bar graph below, showing their relative importance/influence on the model. As expected, **square feet** had lots of influence on house price - living area (`grlivarea`) had the highest coefficient: with every 1 unit increase in (scaled) living area in sf, the (transformed) sale price will increase by 0.793 times. Lot area (`lotarea`), basement area (`bsmtfinsf1`), garage area (`garagearea`) were also within the top 19 predictors. The **year** the house was built also affected house price(`yearbuilt`), as did house **condition** (e.g. `overallqual`,, `bsmtqual`, `kitchenqual`) and **location** (being in Northridge Heights, Stone Brook, and Northridge). All the features are positively correlated with saleprice, except for `age_sold` and `mszoning_c (all)`. For `age_sold`, every (scaled) year's increase in the age of a house corresponds to a -0.297 times decrease in (transformed) price. For `mszoning_C (all)`, houses in this zone (commercial) are 0.119 times cheaper (in terms of transformed price) than others.\n",
    "\n",
    "(If one wants to simplify the model even further, the model can arguably be reduced to just 6 predictors, where there is an obvious 'elbow' in the graph, indicating a less steep decrease in MSE after 6 predictors.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T04:32:58.375502Z",
     "start_time": "2019-10-11T04:32:57.643649Z"
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------- IDENTIFYING TOP FEATURES ----------------------------------------\n",
    "\n",
    "# get list of coefficients that are not 0\n",
    "coef_labels = [col for col in train_dummies.columns if col != 'saleprice'] # column labels\n",
    "enet_coef = pd.DataFrame(enet_mod.coef_, index = coef_labels)              # get coefficients from best model\n",
    "enet_coef = enet_coef[enet_coef[0] != 0]                                   # get non-zero coefficients\n",
    "print(f'the model produced {enet_coef.shape[0]} non-zero coefficients.')\n",
    "\n",
    "# sort by absolute values\n",
    "enet_coef = enet_coef.reindex(enet_coef[0].abs().sort_values(ascending=True).index)\n",
    "\n",
    "# plot title\n",
    "plt.figure(figsize=(8, 0.3))\n",
    "plt.text(x = 0.1,                              \n",
    "         y = 0.9,                             \n",
    "         s = 'model: elastic net', \n",
    "         ha = 'left',                        \n",
    "         va = 'center',                       \n",
    "         size = 15,                            \n",
    "         alpha = 0.8)                         \n",
    "plt.axis('off')\n",
    "\n",
    "# plot top 30 coefficients\n",
    "enet_coef.tail(30).plot.barh(figsize=(15,9), legend = None)\n",
    "plt.title('top 30 features with the highest coefficients',fontsize=14)\n",
    "plt.xlabel('coefficient', fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T04:32:31.228840Z",
     "start_time": "2019-10-11T04:32:23.068427Z"
    }
   },
   "outputs": [],
   "source": [
    "# ------------------ EVALUATING MODEL PERFORMANCE (USING CV) BASED ON NO. OF FEATURES --------------------\n",
    "\n",
    "# put the test data into a dataframe so they can be sliced\n",
    "xtrain_df = pd.DataFrame(xtrain_scaled, columns = coef_labels)\n",
    "    \n",
    "# for each number of predictors in the 104 non-zero predictors, compute validation set error (MSE) and SE\n",
    "# starting from the predictor with the highest coefficient\n",
    "n_predictors = 104\n",
    "mse_mean = []\n",
    "mse_se = []\n",
    "for n in range(1,n_predictors+1):\n",
    "    predictors = enet_coef.index[-n:]  # coefficients are sorted by absolute values, highest at bottom\n",
    "    xtrain_sliced = xtrain_df[predictors]   # slice out just that predictor from xtest_scaled\n",
    "    # get validation set MSE and MSE variance\n",
    "    cv_scores = -cross_val_score(lasso_mod, xtrain_sliced, ytrain, scoring = 'neg_mean_squared_error', cv = 5)\n",
    "    mse_mean.append(cv_scores.mean())\n",
    "    mse_se.append(cv_scores.std()/np.sqrt(5))\n",
    "\n",
    "    \n",
    "# ----------------------------------------- PLOT TITLE ---------------------------------------------------\n",
    "plt.figure(figsize=(8, 0.3))\n",
    "plt.text(x = 0.1,                              \n",
    "         y = 0.9,                             \n",
    "         s = 'model: elastic net', \n",
    "         ha = 'left',                        \n",
    "         va = 'center',                       \n",
    "         size = 15,                            \n",
    "         alpha = 0.8)                         \n",
    "plt.axis('off')\n",
    "\n",
    "# ------------------------- PLOT VALIDATION SET ERROR AGAINST NO. PREDICTORS -----------------------------\n",
    "fig, ax = plt.subplots(ncols = 1, nrows = 2, figsize=(15,13))\n",
    "\n",
    "# PLOT WITH ALL PREDICTORS\n",
    "\n",
    "ax[0].plot(np.arange(1,n_predictors+1,1), mse_mean, 'k', label = 'MSE')\n",
    "# plot error lines showing +/- SE of the MSE\n",
    "ax[0].plot(np.arange(1,n_predictors+1,1),[a+b for a, b in zip(mse_mean,mse_se)], 'b:',\n",
    "        label='+/- 1 SE')\n",
    "ax[0].plot(np.arange(1,n_predictors+1,1),[a-b for a, b, in zip(mse_mean,mse_se)], 'b:')\n",
    "# set fill color between error lines\n",
    "ax[0].fill_between(np.arange(1,n_predictors+1,1), [a+b for a, b in zip(mse_mean,mse_se)],\n",
    "                                   [a-b for a, b in zip(mse_mean,mse_se)], alpha=0.2)\n",
    "ax[0].set_title('mean CV MSE vs number of predictors (n = 106)', fontsize=14)\n",
    "ax[0].set_ylabel('CV MSE  +/- SE', fontsize = 12)\n",
    "ax[0].set_xlabel('number of predictors', fontsize = 12)\n",
    "ax[0].set_xlim(0.5, n_predictors + 0.5)\n",
    "ax[0].legend(loc = 'upper right',  prop={'size': 12})\n",
    "\n",
    "# ZOOMED-IN PLOT WITH 40 PREDICTORS\n",
    "\n",
    "ax[1].plot(np.arange(1,n_predictors+1,1), mse_mean, 'k', label = 'MSE')\n",
    "# plot error lines showing +/- SE of the MSE\n",
    "ax[1].plot(np.arange(1,n_predictors+1,1),[a+b for a, b in zip(mse_mean,mse_se)], 'b:',\n",
    "        label='+/- 1 SE')\n",
    "ax[1].plot(np.arange(1,n_predictors+1,1),[a-b for a, b, in zip(mse_mean,mse_se)], 'b:')\n",
    "# set fill color between error lines\n",
    "ax[1].fill_between(np.arange(1,n_predictors+1,1), [a+b for a, b in zip(mse_mean,mse_se)],\\\n",
    "                                   [a-b for a, b in zip(mse_mean,mse_se)], alpha=0.2)\n",
    "# there does not seem to be significant declines in MSE beyond 30 predictors\n",
    "# plot horizontal line for the MSE of 30 predictors, + 1 SE\n",
    "ax[1].axhline(mse_se[29]+mse_mean[29], linestyle='--', color='r',label = '+ 1 SE from MSE of 30 predictors')\n",
    "ax[1].set_title('mean CV MSE vs number of predictors (n = 50)', fontsize=14)\n",
    "ax[1].set_ylabel('CV MSE  +/- SE', fontsize = 12)\n",
    "ax[1].set_xlabel('number of predictors', fontsize = 12)\n",
    "ax[1].set_xticks(np.arange(1,41,1))\n",
    "ax[1].set_xlim(0.5, 40 + 0.5)\n",
    "ax[1].legend(loc = 'upper right',  prop={'size': 12})\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viewing top 19 features and their coefficients (highest at the bottom, sorted by absolute value)\n",
    "enet_coef.tail(19)\n",
    "\n",
    "# as neighborhood_GrnHill has very few samples in the original data (see below), it will not be used\n",
    "# viewing top 20 features to include the next top predictor\n",
    "enet_coef.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checking sample size for categorical coefficients in the original train df\n",
    "print(train.neighborhood.value_counts())   # NridgeHt, StoneBr, and NoRidge look okay, but GrnHill only has 2\n",
    "print(train.mszoning.value_counts())       # mszoning_c is a bit low \n",
    "print(train.mssubclass.value_counts())     # mssubclass 20 looks okay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of production model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores for the reduced elastic net model using these 19 predictors are:\n",
    "\n",
    "| Model              \t| R2      \t| RMSE    \t|\n",
    "|-------\t            |---------\t|---------\t|\n",
    "| reduced  - train  \t| 0.91200 \t| 0.73577  \t|\n",
    "| reduced - test    \t| 0.90493 \t| 0.77700 \t|\n",
    "| full model - train \t| 0.91808  \t| 0.71047  \t|\n",
    "| full mode - test  \t| 0.91925 \t| 0.71612 \t|\n",
    "\n",
    "Compared to the performance of the full model (with all 104 predictors), the reduced model still gave a relatively good score (with low RMSE and an R<sup>2</sup> score of 0.904 - or being able to account for 90.4% of the variations in sale price) while improving interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get list of top 19 predictors\n",
    "predictors = list(coef_labels.index[-20:])\n",
    "\n",
    "# # remove greenhill, for which predictions may not be accurate due to low sample size\n",
    "predictors.remove('neighborhood_GrnHill')\n",
    "len(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ FIT MODEL TO TEST DATA WITH FEATURES SELECTED FROM ABOVE ------------------\n",
    "\n",
    "# put the data into a dataframe so they can be sliced\n",
    "xtrain_df = pd.DataFrame(xtrain_scaled, columns = coef_labels)\n",
    "xtest_df = pd.DataFrame(xtest_scaled, columns = coef_labels)\n",
    "\n",
    "# slice out selected predictors\n",
    "xtrain_slice = xtrain_df[predictors]\n",
    "xtest_slice = xtest_df[predictors]\n",
    "\n",
    "# CV training score\n",
    "print(crossval(enet, xtrain_slice, ytrain))\n",
    "\n",
    "# fit model to train data\n",
    "enet_mod = enet.fit(xtrain_slice, ytrain)\n",
    "\n",
    "# predict on test data\n",
    "ypred = enet_mod.predict(xtest_slice)\n",
    "\n",
    "# get test scores\n",
    "print('enet test R2: ', enet_mod.score(xtest_slice, ytest))\n",
    "print('enet test RMSE: ', rmse(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Recommendations\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for scatterplot subplots\n",
    "def subplot_scatter(dataframe, list_of_columns):\n",
    "    nrows = int(np.ceil(len(list_of_columns)/4)) \n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=4,figsize=(15, nrows*3.5)) \n",
    "    ax = ax.ravel() \n",
    "    for i, column in enumerate(list_of_columns): \n",
    "        sns.regplot(y=dataframe.saleprice, x=dataframe[column],ax=ax[i], \\\n",
    "                    scatter_kws={'facecolors':'skyblue','edgecolor':'skyblue'},\n",
    "                    line_kws = {'color':'grey'})\n",
    "        ax[i].set_title(f'{column} vs saleprice',fontsize=14)  \n",
    "        ax[i].tick_params(labelsize=12)\n",
    "        ax[i].set_xlabel(column, fontsize=14)\n",
    "        ax[i].set_ylabel('saleprice', fontsize=14)\n",
    "    plt.tight_layout()\n",
    " \n",
    "# scatterplots for top 19 predictors\n",
    "plt.figure(figsize=(8, 0.3))\n",
    "plt.text(x = 1,                              \n",
    "         y = 0.9,                             \n",
    "         s = 'top 19 predictors vs saleprice', \n",
    "         ha = 'center',                        \n",
    "         va = 'center',                       \n",
    "         size = 25,                            \n",
    "         alpha = 0.8)                         \n",
    "plt.axis('off')\n",
    "\n",
    "subplot_scatter(train_dummies, predictors[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An elastic net regression model had the best predictive performance on housing sale price in Ames USA, and outperformed the other linear models tested. As a regularised regression method, it was able to reveal which features affect sale price the most. \n",
    "\n",
    "Square feet area, condition, age, and the location of the house are the most important determinant factors of how much a house sells for (see figure above). As a buyer with a specific budget, the model would allow them to find out what features they would be able to afford, e.g. how big a house they can buy in Northridge with a \\\\$50,000 budget. Houses in Northridge Heights, Stone Brook, and Northridge all had higher prices compared to other neighbourhoods, therefore those looking to invest could consider those areas, whereas houses in the commercial zone and and 2 storey houses (built 1946 and newer) should be avoided.\n",
    "\n",
    "Conversely, people looking to sell their house would be able to use the model to get an estimate of how much they would be able to sell their house for, given the features of the house. If one is looking to sell their house, they should do it sooner rather than later, as the age of the house is the biggest contributing factor to the decrease in value. Having a garage in bad condition also negatively affect value, as does having a second floor to the house. And unsurprisingly, if the house is severely damaged, its value drops. As such, those looking to increase the value of their home could consider (in order of how much each feature affect price):\n",
    "- repainting the interior and exterior of the house to improve overall material and finish quality\n",
    "- renovating the kitchen to improve kitchen quality, e.g. by retiling and adding modern appliances\n",
    "- adding a fireplace (if not already present)\n",
    "- renovating the garage if it is in bad condition\n",
    "- renovating the house if it had been severely damaged\n",
    "\n",
    "However, as the model was developed using data on houses sold between 2006 - 2010 in Ames, USA, it may have limited applicabilities. Firstly, it captures only a small time frame of four years (also with some missing months in each year). This is not enough to capture any annual patterns in sale price that could arise as a result of external factors, such as policy changes, the current economomy and whether or not it is a recession year. It is also unknown whether or not the sale prices had been adjusted for inflation within those years, which would have been a source of variation in saleprice otherwise. As it is currently 2019, house prices may have changed due to one or more of these factors. Therefore this model may not be accurate when applied to present-day data. \n",
    "\n",
    "Secondly, there may also be other factors affecting house price, since the model only accounted for 90.4% of the variations in sale price. The remaining 9.6% could be due to factors related to area desirability (i.e. location). In the current dataset, only neighborhoods and proximity to roads are included under this category. In reality, factors like presence of schools, hospitals, malls, beaches, and the CBD are some examples of other factors that are also likely to affect house price.\n",
    "\n",
    "Lastly, the model is specific to houses in Ames and may not be as accurate when applied to data from another city or country. Variations in cultures mean people in different countries look for different things in a house, which would in turn affect sale price. For example, having a fireplace in a house in Singapore (or anywhere in the tropics) is unlikely to bring the value of the house up, as few people in these places want a fireplace in their house. To make the model more universal, one would need to remove certain Ames- or USA- specific features, such as garage presence, basement presence, and the Ames neighbourhoods. These could be converted to or included in more universal features, such as total square footage.\n",
    "\n",
    "Therefore, to improve the applicability of the model, one can consider adding in more data from a wider time frame, from different locations, and on more universal features. Another improvement would be to analyse the features more closely to see the extent to which they may affect price before there is diminishing returns, e.g. how many fireplaces is economical to add to increase home value, before there are too many fireplaces. Lastly, a lasso model is good for feature selection but is less interpretable than an ordinary linear model, due to the scaling of features. It is difficult for someone to tell immediately, for instance, how much the value of a house would be reduced by with every 1 year increase in age. Therefore, another improvement may be to find a model that performs just as well but is also easy to interprete, so that it will be more readily understood and accepted by the general public.\n",
    "\n",
    "In reality, house price may be difficult to predict as it is also affected by buyers' psychology, the economic climate, and other factors not included in the present dataset. There will never be a perfect model; the aim of this model is therefore not to give a perfect prediction, but act as a guideline to inform decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Submission\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kaggle score (RMSE) for the production model was **27554**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import preprocessed test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the transformations on features have been done in the preprocessing notebook (#2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/test_cleaned.csv')\n",
    "\n",
    "# remove unnamed and index columns\n",
    "test = test.iloc[:, 2:]\n",
    "\n",
    "# convert mssubclass to string again since it got converted back to int on import\n",
    "test['mssubclass'] = test['mssubclass'].astype(str)\n",
    "\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot-encode test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dummies = pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice out selected predictors from the test df\n",
    "test_sliced = test_dummies[predictors]\n",
    "xtrain_sliced = xtrain[predictors]\n",
    "\n",
    "# transforming only\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(xtrain_sliced)\n",
    "test_scaled = scaler.transform(test_sliced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model and predict using test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This uses the [model from above section](#Performance-of-production-model) that had been fitted to the training data with the top 17 predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "ypred = enet_mod.predict(test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check - plot histogram of ypred (transformed)\n",
    "plt.hist(ypred)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert and export predicted test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ypred_untransform = (0.15 + 2)**(1/0.15) - 1\n",
    "\n",
    "# check that there're 879 prediction rows\n",
    "export = pd.DataFrame({'Id': test.id, 'SalePrice': ypred_untransform})\n",
    "print(export.shape)\n",
    "export.to_csv('~/Desktop/DSI/Submissions/Projects/project_2/Ames-housing-price-prediction-master/Ames-housing-price-prediction-master/data/dsir-420-project-2-regression-challenge.csv', index =False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check - plot histogram of ypred (final)\n",
    "plt.hist(ypred_untransform)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-3-bf97e5815d25>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-bf97e5815d25>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    if n in fibonacci_cache[n]\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "fibanacci_cache={}\n",
    "def fibonacci (n):\n",
    "if n in fibonacci_cache[n]\n",
    "    return fibonacci_cache[n]\n",
    "    if n == 1:\n",
    "        value == 1\n",
    "    elif n == 2:\n",
    "        value == 1\n",
    "    elif n > 2:\n",
    "        value  = fibonacci(n-1) + fibonacci(n-2)\n",
    "fibonacci_cache[n] = value\n",
    "return value\n",
    "for n in range (1, 1001):\n",
    "    print (n, ';', fibonacci(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "285px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
